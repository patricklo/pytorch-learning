{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f547ef7f-3405-4367-8f01-f565c468edc5",
   "metadata": {},
   "source": [
    "构建卷积神经网络 RNN\n",
    "- RNN只适用的图像\n",
    "- 卷积网络的输入和层与传统神经网络有些区别，需重新设计，训练模块基本一致\n",
    "- 输入大小： batch_size*1(channel)*28(height)*28(weight)\n",
    "-  传统神经网络用的是Full connection全连接输入一般为： batch_size * 784，然后走全连接(FC)去训练模型和预测\n",
    "   CNN卷积神经网络是适用图像 batch_size*1(channel)*28(height)*28(weight)，走卷积（conv)去训练模型和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b131b74f-a1aa-4841-bf29-920e92359494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patrick\\anaconda3\\envs\\transformer-3\\lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30b93cc6-b87d-43ce-bd5d-f67b4f2447bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''读取数据\n",
    "- 分别构建训练集和测试集（验证集）\n",
    "- DataLoader来迭代取数据\n",
    "'''\n",
    "\n",
    "#定义参数\n",
    "input_size=28 #输入图像的尺寸 28*28\n",
    "num_classes = 10 #标签的总类数\n",
    "num_epochs = 3 #训练的总循环周期\n",
    "batch_size=64 #一个批次的大小， 64张图片\n",
    "#训练集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform = transforms.ToTensor(), download=True)\n",
    "#测试集\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform = transforms.ToTensor())\n",
    "#构建batch数据\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ff904-f2ff-410a-9c07-02e747bd814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''卷积网络模块的构建\n",
    "- 一般卷积层/relu层/池化层可以定成一个套餐\n",
    "- 注意卷积最后结果还是一个特征图，需要把图转换成向量才能做分类或者回归任务\n",
    "'''\n",
    "class MY_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MY_CNN, self).__init__()\n",
    "        '''\n",
    "        PyTorch中要求卷积输入维度为channel first概念，也就是说一张28*28的黑白照片（channel为1)-(28,28,1), 在pytorch要转换成（1，28，28）的维度来作为输入.\n",
    "        因此后续如果读入维度为(28,28,1)需要自己转换为(1,28,28)\n",
    "\n",
    "        ## 2d卷积，也就是2d图像中的height * weight， 3d卷积对应的是视频数据，height*weight*time\n",
    "        \n",
    "        H2 = (H1 - Fh + 2P)/S + 1 = (28-5+2*2)/1 + 1 = 28\n",
    "        W2 = (W1 - Fw + 2P)/S + 1= (28-5+2*2)/1 + 1 = 28\n",
    "\n",
    "        输入维度(1, 28, 28) ->输出维度(16(out_channels) * H2 * W2) = (16, 28, 28)\n",
    "        \n",
    "        '''\n",
    "        self.conv1 = nn.Sequential(   ## <-----输入大小(1,28,28)，其实就是(28,28,1)\n",
    "                                    nn.Conv2d( ## 2d卷积，也就是2d图像中的height * weight， 3d卷积对应的是视频数据，height*weight*time\n",
    "                                            in_channels=1,  #灰度图, 如果是彩色照片RGB那channel是3\n",
    "                                            out_channels=16,  #需要输出多少个特征图 （4*4) - 其实就是卷积核（权重/weight)的个数\n",
    "                                            kernel_size=5, #每个卷积核大小-weight权重的大小 2d卷积对应的是5*5? Fw * Fh = 5 *５\n",
    "                                            stride=1,  #步长　S\n",
    "                                            padding=2), #padding: P, 如果希望卷积后大小和原来一样，padding=(kernel_size-1)/2, if stride = 1_\n",
    "                                      #输出的特征图为（16,28,28)->(28,28,16)  - 16是通道数channel\n",
    "            \n",
    "                                   nn.ReLU(),            #ReLU层/sigmoid层，做完一次特征提取后，都要做一下非线性映射（relu)\n",
    "                                   nn.MaxPool2d(kernel_size=2), #进行池化操作,其实是压缩操作。 (2*2区域）----> 输出为：(16, 28/kernel_size=14, 28/kernel_size=14)\n",
    "                                  )\n",
    "        self.conv2 = nn.Sequential( ##输入为：上面一层的输入： (16,14,14)\n",
    "                                 nn.Conv2d(16,32,5,1,2), ##输出为：(32, 14, 14)\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(32,32,5,1,2), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2), ##输出为：(32, 7, 7)\n",
    "                                  )\n",
    "        self.conv3 = nn.Sequential(\n",
    "                                   nn.Conv2d(32,64,5,1,2),     #输出（64，14，14）\n",
    "                                   nn.ReLU(), \n",
    "                                   #nn.MaxPool2d(kernel_size=2) #输出为：（64，7，7）\n",
    "                                  )\n",
    "\n",
    "        '''\n",
    "        ##全连接：从上面的输出特征图（64＊７＊７）-> wx+b　->　得到１０分类的概率结果 \n",
    "\n",
    "        特征图（64＊７＊７）->拉长为向量（长度为：64*7*7=3136）-> wx+b -> 10分类的概率结果\n",
    "\n",
    "        拉长为向量: (x = x.view(x.size(0), -1) )\n",
    "        '''\n",
    "        self.out = nn.Linear(64 * 7 * 7, 10) ##全连接：从上面的输出（６４＊７＊７）　->　得到１０分类的概率结果 \n",
    "\n",
    "    def forward(self, x):  ##X有4个维度： (batch_size, channel, height, weight) -> (batch_size, 64, 7, 7)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)  ##x.size(0)=batch_size, -1:即自动计算另一个维度大小。跟reshape操作一样，flatten的操作，将(batch_size, 64, 7, 7)的维度转换为：(batch_size, 64*7*7) \n",
    "        output = self.out(x) #全连接，得出结果。\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab1a709a-f95b-42b0-8942-f4e7dc3264f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1]  #得结果当中，值最大的值\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()  #看pred值 跟labels是不是相等的。\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8efb1499-f579-4d99-9dc7-e0d5933e6746",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x576 and 3136x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     13\u001b[0m     net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 14\u001b[0m     output\u001b[38;5;241m=\u001b[39m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\transformer-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\transformer-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[24], line 59\u001b[0m, in \u001b[0;36mMY_CNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n\u001b[0;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m##x.size(0)=batch_size, -1:即自动计算另一个维度大小。跟reshape操作一样，flatten的操作，将(batch_size, 64, 7, 7)的维度转换为：(batch_size, 64*7*7) \u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#全连接，得出结果。\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\transformer-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\transformer-3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\transformer-3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x576 and 3136x10)"
     ]
    }
   ],
   "source": [
    "#实例化\n",
    "net = MY_CNN()\n",
    "#损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01) #定义优化器，普通的随机梯度下降算法\n",
    "\n",
    "#开始训练的循环\n",
    "for epoch in range(num_epochs):\n",
    "    #把当前epoch的结果保存下来\n",
    "    train_rights = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #训练\n",
    "        net.train()\n",
    "        output=net(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output, target)\n",
    "        train_rights.append(right)\n",
    "\n",
    "        if batch_idx % 100 ==0:\n",
    "            #验证\n",
    "            net.eval()\n",
    "            val_rights =[]\n",
    "            for (data,target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output, target)\n",
    "                val_rights.append(right)\n",
    "            #准确率计算\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "\n",
    "            print('当前epoch: {} [{}/{} ({:.0f}%)]\\t损失: {:.6f}\\t训练集准确率: {:.2f}%\\t测试集正确率: {:.2f}%'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.data, \n",
    "                100. * train_r[0].numpy() / train_r[1], \n",
    "                100. * val_r[0].numpy() / val_r[1]))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672d2a4-47d9-40e0-9312-bd009658da95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
