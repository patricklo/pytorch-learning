{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f547ef7f-3405-4367-8f01-f565c468edc5",
   "metadata": {},
   "source": [
    "构建卷积神经网络 RNN\n",
    "- RNN只适用的图像\n",
    "- 卷积网络的输入和层与传统神经网络有些区别，需重新设计，训练模块基本一致\n",
    "- 输入大小： batch_size*1(channel)*28(height)*28(weight)\n",
    "-  传统神经网络用的是Full connection全连接输入一般为： batch_size * 784，然后走全连接(FC)去训练模型和预测\n",
    "   CNN卷积神经网络是适用图像 batch_size*1(channel)*28(height)*28(weight)，走卷积（conv)去训练模型和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b131b74f-a1aa-4841-bf29-920e92359494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patrick\\anaconda3\\envs\\transformer-3\\lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b93cc6-b87d-43ce-bd5d-f67b4f2447bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:07<00:00, 1.30MB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 146kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:01<00:00, 1.15MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "'''读取数据\n",
    "- 分别构建训练集和测试集（验证集）\n",
    "- DataLoader来迭代取数据\n",
    "'''\n",
    "\n",
    "#定义参数\n",
    "input_size=28 #输入图像的尺寸 28*28\n",
    "num_classes = 10 #标签的总类数\n",
    "num_epochs = 3 #训练的总循环周期\n",
    "batch_size=64 #一个批次的大小， 64张图片\n",
    "#训练集\n",
    "train_dataset = datasets. MNIST(root='./data', train=True, transform = transforms.ToTensor(), download=True)\n",
    "#测试集\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform = transforms.ToTensor())\n",
    "#构建batch数据\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88bab1b-2b81-4177-a67b-ead8fe43cd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2e5a9cdac40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929ff904-f2ff-410a-9c07-02e747bd814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''卷积网络模块的构建\n",
    "- 一般卷积层/relu层/池化层可以定成一个套餐\n",
    "- 注意卷积最后结果还是一个特征图，需要把图转换成向量才能做分类或者回归任务\n",
    "'''\n",
    "class MY_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MY_CNN, self).__init__()\n",
    "        '''\n",
    "        PyTorch中要求卷积输入维度为channel first概念，也就是说一张28*28的黑白照片（channel为1)-(28,28,1), 在pytorch要转换成（1，28，28）的维度来作为输入.\n",
    "        因此后续如果读入维度为(28,28,1)需要自己转换为(1,28,28)\n",
    "\n",
    "        ## 2d卷积，也就是2d图像中的height * weight， 3d卷积对应的是视频数据，height*weight*time\n",
    "        \n",
    "        H2 = (H1 - Fh + 2P)/S + 1 = (28-5+2*2)/1 + 1 = 28\n",
    "        W2 = (W1 - Fw + 2P)/S + 1= (28-5+2*2)/1 + 1 = 28\n",
    "\n",
    "        输入维度(1, 28, 28) ->输出维度(16(out_channels) * H2 * W2) = (16, 28, 28)\n",
    "        \n",
    "        '''\n",
    "        self.conv1 = nn.Sequential(   ## <-----输入大小(1,28,28)，其实就是(28,28,1)\n",
    "                                    #卷积层\n",
    "                                    nn.Conv2d( ## 2d卷积，也就是2d图像中的height * weight， 3d卷积对应的是视频数据，height*weight*time\n",
    "                                            in_channels=1,  #灰度图, 如果是彩色照片RGB那channel是3\n",
    "                                            out_channels=16,  #需要输出多少个特征图 （4*4) - 其实就是卷积核（权重/weight)的个数\n",
    "                                            kernel_size=5, #每个卷积核大小-weight权重的大小 2d卷积对应的是5*5? Fw * Fh = 5 *５\n",
    "                                            stride=1,  #步长　S\n",
    "                                            padding=2), #padding: P, 如果希望卷积后大小和原来一样，padding=(kernel_size-1)/2, if stride = 1_\n",
    "                                      #输出的特征图为（16,28,28)->(28,28,16)  - 16是通道数channel\n",
    "                                    #relu层\n",
    "                                   nn.ReLU(),            #ReLU层/sigmoid层，做完一次特征提取后，都要做一下非线性映射（relu)\n",
    "                                   #池化层\n",
    "                                  #进行池化操作,其实是压缩操作。 (2*2区域）----> 输出为：(16, 28/kernel_size=14, 28/kernel_size=14)\n",
    "                                   nn.MaxPool2d(kernel_size=2), \n",
    "                                 \n",
    "                                  )\n",
    "        self.conv2 = nn.Sequential( ##输入为：上面一层的输入： (16,14,14)\n",
    "                                 nn.Conv2d(16,32,5,1,2), ##输出为：(32, 14, 14)\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(32,32,5,1,2), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2), ##输出为：(32, 7, 7)\n",
    "                                  )\n",
    "        self.conv3 = nn.Sequential(  #下一个套餐的输入为(16,14,14)\n",
    "                                   nn.Conv2d(32,64,5,1,2),     #输出（64，14，14）\n",
    "                                   nn.ReLU(),  #输出（64，7，7）\n",
    "                                   #nn.MaxPool2d(kernel_size=2) #输出为：（64，7，7）\n",
    "                                  )\n",
    "        '''\n",
    "        ##全连接：从上面的输出特征图（64＊７＊７）-> wx+b　->　得到１０分类的概率结果 \n",
    "\n",
    "        特征图（64＊７＊７）->拉长为向量（长度为：64*7*7=3136）-> wx+b -> 10分类的概率结果\n",
    "\n",
    "        拉长为向量: (x = x.view(x.size(0), -1) )\n",
    "        '''\n",
    "       \n",
    "        self.out = nn.Linear(64 * 7 * 7, 10) ##全连接：从上面的输出（６４＊７＊７）　->　得到１０分类的概率结果 \n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, x):  ##X有4个维度： (batch_size, channel, height, weight) -> (batch_size, 64, 7, 7)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        #print('x.size=',x.size(0))\n",
    "        x = x.view(x.size(0), -1)  #跟reshape操作一样，将（64*7*7）的数据转换成2维数据 (65 , 49)\n",
    "        output = self.out(x) #全连接，得出结果。\n",
    "        '''\n",
    "        x.view(x.size(0), -1)\n",
    "        \n",
    "        x.size(0)=batch_size, \n",
    "        -1:即自动计算另一个维度大小。\n",
    "        \n",
    "        跟reshape操作一样，flatten的操作，将(batch_size, 64, 7, 7)的维度转换为：(batch_size, 64*7*7) \n",
    "        '''\n",
    "        return output\n",
    "        \n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab1a709a-f95b-42b0-8942-f4e7dc3264f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1]  #得结果当中，值最大的值. torch.max会返回dict(max_index, max_value)\n",
    "    '''\n",
    "    labels.data.view_as(pred)  - > labels reshape操作，确保维度跟pred一致，才能做比较\n",
    "    '''\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()  #看pred值 跟labels是不是相等的。\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8efb1499-f579-4d99-9dc7-e0d5933e6746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前epoch: 0 [0/60000 (0%)]\t损失: 2.304833\t训练集准确率: 6.25%\t测试集正确率: 18.19%\n",
      "当前epoch: 0 [6400/60000 (11%)]\t损失: 0.272444\t训练集准确率: 77.49%\t测试集正确率: 91.38%\n",
      "当前epoch: 0 [12800/60000 (21%)]\t损失: 0.420387\t训练集准确率: 85.77%\t测试集正确率: 95.86%\n",
      "当前epoch: 0 [19200/60000 (32%)]\t损失: 0.246342\t训练集准确率: 89.14%\t测试集正确率: 97.11%\n",
      "当前epoch: 0 [25600/60000 (43%)]\t损失: 0.019930\t训练集准确率: 91.10%\t测试集正确率: 97.65%\n",
      "当前epoch: 0 [32000/60000 (53%)]\t损失: 0.031573\t训练集准确率: 92.36%\t测试集正确率: 97.18%\n",
      "当前epoch: 0 [38400/60000 (64%)]\t损失: 0.058093\t训练集准确率: 93.22%\t测试集正确率: 97.85%\n",
      "当前epoch: 0 [44800/60000 (75%)]\t损失: 0.152117\t训练集准确率: 93.91%\t测试集正确率: 98.16%\n",
      "当前epoch: 0 [51200/60000 (85%)]\t损失: 0.051793\t训练集准确率: 94.35%\t测试集正确率: 98.37%\n",
      "当前epoch: 0 [57600/60000 (96%)]\t损失: 0.067726\t训练集准确率: 94.75%\t测试集正确率: 98.45%\n",
      "当前epoch: 1 [0/60000 (0%)]\t损失: 0.028577\t训练集准确率: 98.44%\t测试集正确率: 98.68%\n",
      "当前epoch: 1 [6400/60000 (11%)]\t损失: 0.023530\t训练集准确率: 98.79%\t测试集正确率: 98.76%\n",
      "当前epoch: 1 [12800/60000 (21%)]\t损失: 0.094553\t训练集准确率: 98.64%\t测试集正确率: 98.74%\n",
      "当前epoch: 1 [19200/60000 (32%)]\t损失: 0.136828\t训练集准确率: 98.54%\t测试集正确率: 98.59%\n",
      "当前epoch: 1 [25600/60000 (43%)]\t损失: 0.003777\t训练集准确率: 98.55%\t测试集正确率: 98.64%\n",
      "当前epoch: 1 [32000/60000 (53%)]\t损失: 0.050579\t训练集准确率: 98.53%\t测试集正确率: 98.44%\n",
      "当前epoch: 1 [38400/60000 (64%)]\t损失: 0.006985\t训练集准确率: 98.56%\t测试集正确率: 97.99%\n",
      "当前epoch: 1 [44800/60000 (75%)]\t损失: 0.093686\t训练集准确率: 98.60%\t测试集正确率: 99.01%\n",
      "当前epoch: 1 [51200/60000 (85%)]\t损失: 0.004518\t训练集准确率: 98.61%\t测试集正确率: 98.81%\n",
      "当前epoch: 1 [57600/60000 (96%)]\t损失: 0.006520\t训练集准确率: 98.64%\t测试集正确率: 98.99%\n",
      "当前epoch: 2 [0/60000 (0%)]\t损失: 0.018243\t训练集准确率: 98.44%\t测试集正确率: 99.04%\n",
      "当前epoch: 2 [6400/60000 (11%)]\t损失: 0.006918\t训练集准确率: 99.13%\t测试集正确率: 98.93%\n",
      "当前epoch: 2 [12800/60000 (21%)]\t损失: 0.007412\t训练集准确率: 99.11%\t测试集正确率: 98.60%\n",
      "当前epoch: 2 [19200/60000 (32%)]\t损失: 0.047267\t训练集准确率: 99.08%\t测试集正确率: 99.11%\n",
      "当前epoch: 2 [25600/60000 (43%)]\t损失: 0.007713\t训练集准确率: 99.08%\t测试集正确率: 98.99%\n",
      "当前epoch: 2 [32000/60000 (53%)]\t损失: 0.032205\t训练集准确率: 99.07%\t测试集正确率: 98.94%\n",
      "当前epoch: 2 [38400/60000 (64%)]\t损失: 0.017633\t训练集准确率: 99.05%\t测试集正确率: 99.01%\n",
      "当前epoch: 2 [44800/60000 (75%)]\t损失: 0.055055\t训练集准确率: 99.04%\t测试集正确率: 98.60%\n",
      "当前epoch: 2 [51200/60000 (85%)]\t损失: 0.023010\t训练集准确率: 99.04%\t测试集正确率: 99.01%\n",
      "当前epoch: 2 [57600/60000 (96%)]\t损失: 0.005669\t训练集准确率: 99.02%\t测试集正确率: 98.83%\n"
     ]
    }
   ],
   "source": [
    "#实例化\n",
    "net = MY_CNN()\n",
    "#损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#优化器，用于更新CNN中的参数\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) #定义优化器，普通的随机梯度下降算法\n",
    "\n",
    "#开始训练的循环\n",
    "for epoch in range(num_epochs):\n",
    "    #把当前epoch的结果保存下来\n",
    "    train_rights = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): ##batch_idx是enumerate自动出来的一个计数\n",
    "        #训练\n",
    "        net.train()\n",
    "        output=net(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print('output shape=', output.shape)\n",
    "        #print('target shape=', target.shape)\n",
    "        right = accuracy(output, target)\n",
    "        train_rights.append(right)\n",
    "\n",
    "        if batch_idx % 100 ==0:\n",
    "            #验证\n",
    "            net.eval()\n",
    "            val_rights =[]\n",
    "            for (data,target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output, target)\n",
    "                val_rights.append(right)\n",
    "            #准确率计算\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "\n",
    "            print('当前epoch: {} [{}/{} ({:.0f}%)]\\t损失: {:.6f}\\t训练集准确率: {:.2f}%\\t测试集正确率: {:.2f}%'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.data, \n",
    "                100. * train_r[0].numpy() / train_r[1], \n",
    "                100. * val_r[0].numpy() / val_r[1]))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672d2a4-47d9-40e0-9312-bd009658da95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
